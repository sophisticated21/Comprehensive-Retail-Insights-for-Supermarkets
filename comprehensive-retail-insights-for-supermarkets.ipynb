{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4430869,"sourceType":"datasetVersion","datasetId":2594918}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"text-align: center; font-size: 150%; margin-bottom: 20px;\">\n    <h1 style=\"color: #9B60A1;\">Comprehensive Retail Insights for Supermarkets</h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; padding: 15px; background-color: rgba(173, 216, 230, 0.5); font-size: 130%; text-align: left;\">\n<h2 align=\"left\"><font color=\"#9B60A1\">Overview:</font></h2>\n\nIn this comprehensive analysis project, we delve into a dataset covering retail sales across various states and cities in the United States, examining different categories, sub-categories, and shipping modes. This dataset offers a panoramic view of the retail landscape, enabling us to pinpoint which regions and product types are outperforming or underperforming in terms of sales and profit margins.\n\nOur goal is to decipher the underlying patterns in retail performance, thereby assisting stakeholders in making informed decisions to bolster marketing strategies and enhance overall profitability. Through meticulous examination, we aim to identify the top and bottom performers in every category, from geographic locations to shipping methods, providing a clear picture of the retail dynamics at play.\n\nBy employing detailed data visualization techniques and analytical reasoning, we shed light on the variances in sales achievements and profit margins. This enables a targeted approach in areas such as inventory management, pricing strategies, and customer service improvements.\n\nDataset available at [Retail Supermarket dataset on Kaggle](https://www.kaggle.com/datasets/roopacalistus/superstore/data)\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"initialization\"></a>\n<div style=\"background-color: rgba(173, 216, 230, 0.7); color:#9B60A1; font-size:200%; font-family:'Comic Sans MS', cursive, sans-serif; text-align:center; border-radius:20px; padding:10px; box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);\">\n    <span style='color:#0b8549;'>Step 1 |</span><span style='color: #9B60A;'> Initialization</span>\n</div>\n<a href=\"#contents_tabel\" style=\"display:block; text-align:center; margin-top:10px; text-decoration:none; color:#9B60A1; font-family:'Comic Sans MS', cursive, sans-serif;\">⬆️ Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n<div style=\"background-color: rgba(173, 216, 230, 0.7); color:#0b8549; font-size:140%; font-family:'Comic Sans MS', cursive, sans-serif; text-align:center; border-radius:20px; padding:10px; box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);\">\n    <span style='color:#0b8549;'>Step 1.1 |</span><span style='color:#9B60A1;'> Importing Necessary Libraries</span>\n</div>\n<a href=\"#contents_tabel\" style=\"display:block; text-align:center; margin-top:10px; text-decoration:none; color:#9B60A1; font-family:'Comic Sans MS', cursive, sans-serif;\">⬆️ Table of Contents</a>\n","metadata":{}},{"cell_type":"code","source":"# Data manipulation\n#====================\nimport os\nimport pandas as pd\nimport numpy as np\npd.set_option(\"display.max_columns\", None)\n\n# Data visualization\n#====================\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nimport seaborn as sns\nfrom matplotlib import patches\n\n# Widget\n#====================\nimport ipywidgets as widgets\nfrom IPython.display import display","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"load_dataset\"></a>\n<div style=\"background-color: rgba(173, 216, 230, 0.7); color:#0b8549; font-size:140%; font-family:'Comic Sans MS', cursive, sans-serif; text-align:center; border-radius:20px; padding:10px; box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);\">\n    <span style='#fcc36d;'>Step 1.2 |</span><span style='color:#9B60A1;'> Loading the Dataset</span>\n</div>\n<a href=\"#contents_tabel\" style=\"display:block; text-align:center; margin-top:10px; text-decoration:none; color:#9B60A1; font-family:'Comic Sans MS', cursive, sans-serif;\">⬆️ Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"path = '/kaggle/input/superstore/SampleSuperstore.csv'\ndf_original = pd.read_csv(path)\n\ndf = df_original.copy()\ntarget = 'Profit'\ndf.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"OverviewDataCleaning\"></a>\n<div style=\"background-color: rgba(173, 216, 230, 0.7); color:#9B60A1; font-size:200%; font-family:'Comic Sans MS', cursive, sans-serif; text-align:center; border-radius:20px; padding:10px; box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);\">\n    <span style='color:#0b8549;'>Step 2 |</span><span style='color: #9B60A;'> Overview and Data Cleaning</span>\n</div>\n<a href=\"#contents_tabel\" style=\"display:block; text-align:center; margin-top:10px; text-decoration:none; color:#9B60A1; font-family:'Comic Sans MS', cursive, sans-serif;\">⬆️ Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"overview\"></a>\n<div style=\"background-color: rgba(173, 216, 230, 0.7); color:#0b8549; font-size:140%; font-family:'Comic Sans MS', cursive, sans-serif; text-align:center; border-radius:20px; padding:10px; box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);\">\n    <span style='#fcc36d;'>Step 2.1 |</span><span style='color:#9B60A1;'> Overview</span>\n</div>\n<a href=\"#contents_tabel\" style=\"display:block; text-align:center; margin-top:10px; text-decoration:none; color:#9B60A1; font-family:'Comic Sans MS', cursive, sans-serif;\">⬆️ Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"print(\"#\" * 50)\nprint(\" \" * 15, \"Dataset Information\")\nprint(\"#\" * 50)\nprint(\"The Dataset has {} columns and {} rows.\".format(df.shape[1], df.shape[0]))\nprint(\"The DataFrame has {} duplicated values and {} missing values.\".format(df.duplicated().sum(), df.isnull().sum().sum()))\nprint(df.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"Duplicates\"></a>\n<div style=\"background-color: rgba(173, 216, 230, 0.7); color:#0b8549; font-size:140%; font-family:'Comic Sans MS', cursive, sans-serif; text-align:center; border-radius:20px; padding:10px; box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);\">\n    <span style='#fcc36d;'>Step 2.2 |</span><span style='color:#9B60A1;'> Data Cleaning (Handling Duplicates)</span>\n</div>\n<a href=\"#contents_tabel\" style=\"display:block; text-align:center; margin-top:10px; text-decoration:none; color:#9B60A1; font-family:'Comic Sans MS', cursive, sans-serif;\">⬆️ Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"df.drop_duplicates(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"LogicalTest\"></a>\n<div style=\"background-color: rgba(173, 216, 230, 0.7); color:#0b8549; font-size:140%; font-family:'Comic Sans MS', cursive, sans-serif; text-align:center; border-radius:20px; padding:10px; box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);\">\n    <span style='#fcc36d;'>Step 2.3 |</span><span style='color:#9B60A1;'> Data Cleaning (Logical Test)</span>\n</div>\n<a href=\"#contents_tabel\" style=\"display:block; text-align:center; margin-top:10px; text-decoration:none; color:#9B60A1; font-family:'Comic Sans MS', cursive, sans-serif;\">⬆️ Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"def columns_mustbe_positive(data, column):\n\n    \"\"\"\n    Converts negative values to positive and removes zero values in a specific column.\n\n    Args:\n    data (DataFrame): The dataset to be processed.\n    column (str): The name of the column to be processed.\n    \"\"\"\n    \n    #Take the absoulate values\n    data[column] = data[column].abs()\n    \n    # Remove zero values\n    data = data[data[column] != 0]\n    print(\"Corrected {} column: \\n\".format(column))\n    print(data[column].describe())\n    return data\n\ncolumns_mustbe_positive(df, 'Sales')\ncolumns_mustbe_positive(df, 'Quantity')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"Outliers\"></a>\n<div style=\"background-color: rgba(173, 216, 230, 0.7); color:#0b8549; font-size:140%; font-family:'Comic Sans MS', cursive, sans-serif; text-align:center; border-radius:20px; padding:10px; box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);\">\n    <span style='#fcc36d;'>Step 2.4 |</span><span style='color:#9B60A1;'> Data Cleaning (Outlier Check)</span>\n</div>\n<a href=\"#contents_tabel\" style=\"display:block; text-align:center; margin-top:10px; text-decoration:none; color:#9B60A1; font-family:'Comic Sans MS', cursive, sans-serif;\">⬆️ Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"# Create columns for outlier check\ndef mark_outliers(val):\n    Q1 = val.quantile(0.25)\n    Q3 = val.quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    return (val < lower_bound) | (val > upper_bound)\n\n# 'Quantity_Outlier' column\ndf['Quantity_Outlier'] = mark_outliers(df['Quantity']).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['Quantity_Outlier'] == 1].shape[0]\n\ndf[df['Quantity_Outlier'] == 1].head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; padding: 15px; background-color: rgba(173, 216, 230, 0.5); font-size: 100%; text-align: left;\">\n\nWe believe that Quantity = 14 is not too much. So, it seems that outliers column would not be effective. We will drop it.\n\n</div>\n\n","metadata":{}},{"cell_type":"code","source":"df.drop('Quantity_Outlier', axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"ExploreCategoricalColumns\"></a>\n<div style=\"background-color: rgba(173, 216, 230, 0.7); color:#0b8549; font-size:140%; font-family:'Comic Sans MS', cursive, sans-serif; text-align:center; border-radius:20px; padding:10px; box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);\">\n    <span style='#fcc36d;'>Step 2.5 |</span><span style='color:#9B60A1;'> Data Cleaning (Explore Categorical Columns)</span>\n</div>\n<a href=\"#contents_tabel\" style=\"display:block; text-align:center; margin-top:10px; text-decoration:none; color:#9B60A1; font-family:'Comic Sans MS', cursive, sans-serif;\">⬆️ Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"# Explore Categorical Columns\n\n# Select categorical columns\ncategorical_columns = df.select_dtypes(include=['object', 'category'])\n\n# Create a DataFrame from categorical columns with their unique values\ncat_feature_info = pd.DataFrame(columns=['Feature', 'Unique_Values', 'Num_Unique_Values'])\nfor cat_feat in categorical_columns:\n    unique_values = df[cat_feat].unique()\n    num_unique_values = len(unique_values)  # Number of unique values\n    cat_feature_info = pd.concat([cat_feature_info, \n                                  pd.DataFrame({'Feature': cat_feat, \n                                                'Unique_Values': [unique_values],\n                                                'Num_Unique_Values': [num_unique_values]})], \n                                 ignore_index=True)\n\ndisplay(cat_feature_info)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(['Country', 'Postal Code'], axis=1, inplace=True) # The only country is United States. Also no need to postal code","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"DataAnalysis\"></a>\n<div style=\"background-color: rgba(173, 216, 230, 0.7); color:#9B60A1; font-size:200%; font-family:'Comic Sans MS', cursive, sans-serif; text-align:center; border-radius:20px; padding:10px; box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);\">\n    <span style='color:#0b8549;'>Step 3 |</span><span style='color: #9B60A;'> Data Analysis</span>\n</div>\n<a href=\"#contents_tabel\" style=\"display:block; text-align:center; margin-top:10px; text-decoration:none; color:#9B60A1; font-family:'Comic Sans MS', cursive, sans-serif;\">⬆️ Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"Distibutions\"></a>\n<div style=\"background-color: rgba(173, 216, 230, 0.7); color:#0b8549; font-size:140%; font-family:'Comic Sans MS', cursive, sans-serif; text-align:center; border-radius:20px; padding:10px; box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);\">\n    <span style='#fcc36d;'>Step 3.1 |</span><span style='color:#9B60A1;'> Data Analysis (Distributions)</span>\n</div>\n<a href=\"#contents_tabel\" style=\"display:block; text-align:center; margin-top:10px; text-decoration:none; color:#9B60A1; font-family:'Comic Sans MS', cursive, sans-serif;\">⬆️ Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"# Visualize Categorical Columns ( Pie Chart )\ncategorical_features = categorical_columns.drop(['Country', 'City', 'State', 'Sub-Category'], axis=1).columns.tolist()\ndef autopct_fun(abs_values):\n    gen = iter(abs_values)\n    return lambda pct: f\"{pct:.1f}%\\n({next(gen)})\"\n\nyes_color = '#FF6666'  \nno_color = '#6699FF'  \n\nif target in categorical_features:\n    categorical_features.insert(0, categorical_features.pop(categorical_features.index(target)))\n\nfig, ax = plt.subplots(nrows=(len(categorical_features) // 2) + 1, ncols=2, figsize=(20, 40))\nax = ax.flat\n\nfor i, cat_feat in enumerate(categorical_features):\n    df_class = df[cat_feat].value_counts()\n    labels = df_class.index.tolist()\n    values = df_class.values.tolist()\n    unique_labels = len(labels)  \n    colors = [yes_color if label == 'Yes' else no_color if label == 'No' else plt.cm.tab20(j % 20) for j, label in enumerate(labels)]\n    \n    legend_elements = [patches.Patch(color=colors[j], label=labels[j]) for j in range(len(labels))]\n    legend_elements = sorted(legend_elements, key=lambda x: labels[legend_elements.index(x)] != 'Yes', reverse=True)\n\n    ax[i].pie(values, labels=labels, autopct=autopct_fun(values), shadow=True, startangle=90,\n              colors=colors, textprops={'fontsize': 12})\n    ax[i].set_title(f\"{cat_feat}{' (target)' if cat_feat == target else ''}\", fontsize=15, fontweight=\"bold\")\n    ax[i].axis('equal')\n    ax[i].legend(handles=legend_elements, loc='best')\n\nfor j in range(i + 1, len(ax)):\n    ax[j].set_visible(False)\n\nplt.subplots_adjust(left=0.1, right=0.9, top=0.5, bottom=0.1, hspace=0.3, wspace=0.3)\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; padding: 15px; background-color: rgba(173, 216, 230, 0.5); font-size: 100%; text-align: left;\">\n\n__Region Pie Chart:__ Shows the distribution of sales across different regions, highlighting the West as the leading region in sales, followed closely by the East. This suggests a strong market presence in these areas.  \n    \n__Category Pie Chart:__ Illustrates that Office Supplies dominate the sales category, making up over half of the total sales. Technology, despite being the smallest portion, potentially offers higher value per sale given its nature.  \n    \n__Ship Mode Pie Chart:__ Reveals that Standard Class is the most preferred shipping mode, accounting for nearly 60% of shipments. This indicates a customer preference for cost-effectiveness over speed.  \n\n__Segment Pie Chart:__ Displays that the Consumer segment is the largest customer base, contributing to more than half of the sales. This suggests that strategies focusing on the consumer market could be particularly effective.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"TopPerformers\"></a>\n<div style=\"background-color: rgba(173, 216, 230, 0.7); color:#0b8549; font-size:140%; font-family:'Comic Sans MS', cursive, sans-serif; text-align:center; border-radius:20px; padding:10px; box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);\">\n    <span style='#fcc36d;'>Step 3.2 |</span><span style='color:#9B60A1;'> Data Analysis (Top Performers)</span>\n</div>\n<a href=\"#contents_tabel\" style=\"display:block; text-align:center; margin-top:10px; text-decoration:none; color:#9B60A1; font-family:'Comic Sans MS', cursive, sans-serif;\">⬆️ Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"def bar_plot_top_bottom_values(data, column, top=True, top_n=10, ascending=False, orientation='horizontal'):\n    \"\"\"\n    Visualizes the most frequent values and their counts in a given column using a bar chart.\n\n    Args:\n    data (DataFrame): The dataset to be processed.\n    column (str): The name of the column to be used in the chart.\n    top_n (int, optional): The number of top values to display. Defaults to 10.\n    ascending (bool, optional): Whether to reverse the order of the data. Defaults to False.\n    orientation (str, optional): The orientation of the bar chart 'horizontal' or 'vertical'. Defaults to 'horizontal'.\n    \"\"\"\n    plt.figure(figsize=(10, 6))\n    \n    # Decide whether to show top or bottom values\n    if top:\n        top_values = data[column].value_counts().nlargest(top_n)\n    else:\n        top_values = data[column].value_counts().nsmallest(top_n)\n    \n    if orientation == 'horizontal':\n        plt.barh(top_values.index.astype(str), top_values.values, color='#9B60A1')\n        plt.xlabel('Count')\n        plt.ylabel(column)\n        plt.gca().invert_yaxis()  # Sort the bars from highest to lowest value if horizontal\n    elif orientation == 'vertical':\n        plt.bar(top_values.index.astype(str), top_values.values, color='#9B60A1')\n        plt.xlabel(column)\n        plt.ylabel('Count')\n        \n    # Background color\n    plt.gca().set_facecolor((173/255, 216/255, 230/255, 0.5))\n    \n    # Set title\n    plt.title(f'{\"Top\" if top else \"Bottom\"} {top_n} Values in {column}')\n    \n    # Show\n    plt.show()\nbar_plot_top_bottom_values(df, 'State', top=True, top_n=10)\nbar_plot_top_bottom_values(df, 'State', top=False, top_n=10)\nbar_plot_top_bottom_values(df, 'Sub-Category', top=True, top_n=17)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; padding: 15px; background-color: rgba(173, 216, 230, 0.5); font-size: 100%; text-align: left;\">\n    \n__The first chart__ showcases the states with the highest sales volumes, indicating a strong market presence in California, New York, and Texas. The significant lead of California suggests it's a key player in the retail landscape, possibly due to its large population and economic size. This data can guide targeted marketing and expansion strategies, focusing on the most lucrative states. \n\n__The second chart__, contrastingly, highlights states with the lowest sales, including Wyoming, West Virginia, and North Dakota. The limited sales in these areas might reflect smaller markets or less retail activity. Understanding the reasons behind low performance in these states could uncover opportunities for growth or reveal challenges specific to these markets.\n\n__Based on the third chart__, the distribution of sales across sub-categories reveals Binders, Paper, and Furnishings lead in sales volume. This insight into product popularity can inform inventory decisions, marketing focus, and product development. The high sales in Binders and Paper suggest office supplies remain a staple demand among consumers.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"ByShipMode\"></a>\n<div style=\"background-color: rgba(173, 216, 230, 0.7); color:#0b8549; font-size:140%; font-family:'Comic Sans MS', cursive, sans-serif; text-align:center; border-radius:20px; padding:10px; box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);\">\n    <span style='#fcc36d;'>Step 3.3 |</span><span style='color:#9B60A1;'> Data Analysis (Sales, Profits and Profit Margin by Ship Mode)</span>\n</div>\n<a href=\"#contents_tabel\" style=\"display:block; text-align:center; margin-top:10px; text-decoration:none; color:#9B60A1; font-family:'Comic Sans MS', cursive, sans-serif;\">⬆️ Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"#Group sales and profit by shipping modes\nship_mode_analysis = df.groupby('Ship Mode').agg({'Sales':'sum', 'Profit':'sum'}).reset_index()\n\n#Visualize sales and profit with a bar chart\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Ship Mode', y='Sales', data=ship_mode_analysis, color='#9B60A1', label='Sales')\nsns.barplot(x='Ship Mode', y='Profit', data=ship_mode_analysis, color='salmon', label='Profit')\nplt.title('Sales and Profit by Ship Mode')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculate profit margin and add to DataFrame\nship_mode_analysis['Profit Margin'] = (ship_mode_analysis['Profit'] / ship_mode_analysis['Sales']) * 100\n\n#Visualize profit margin\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Ship Mode', y='Profit Margin', data=ship_mode_analysis, palette='magma')\nplt.title('Profit Margin by Ship Mode')\nplt.ylabel('Profit Margin (%)')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; padding: 15px; background-color: rgba(173, 216, 230, 0.5); font-size: 100%; text-align: left;\">\n    \n__The first chart shows__ sales and profits across various shipping modes, revealing Standard Class as the predominant choice, significantly leading in both sales and profit. Although First Class and Second Class show respectable sales, their profit contributions are comparatively lower, with Same Day shipping showing the least impact. __This suggests a strong customer preference for Standard Class, likely due to its balance of cost and delivery speed, which also appears to be the most profitable for the retailer.__  \n\n__The profit margin analysis__ further refines our understanding, displaying a relatively even distribution of profit margins across the shipping modes, with First Class slightly leading. __This uniformity suggests that while the volume and total profit from Standard Class are highest due to its popularity, the efficiency or cost-effectiveness of each mode in terms of margin is fairly consistent. The slight edge of First Class in profit margin might indicate a premium pricing strategy that does not deter its customer base.__","metadata":{}},{"cell_type":"markdown","source":"<a id=\"CustomerSegment\"></a>\n<div style=\"background-color: rgba(173, 216, 230, 0.7); color:#0b8549; font-size:140%; font-family:'Comic Sans MS', cursive, sans-serif; text-align:center; border-radius:20px; padding:10px; box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);\">\n    <span style='#fcc36d;'>Step 3.4 |</span><span style='color:#9B60A1;'> Data Analysis (Sales, Profits and Profit Margin by Customer Segment)</span>\n</div>\n<a href=\"#contents_tabel\" style=\"display:block; text-align:center; margin-top:10px; text-decoration:none; color:#9B60A1; font-family:'Comic Sans MS', cursive, sans-serif;\">⬆️ Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"# Group sales and profit by segments\nsegment_analysis = df.groupby('Segment').agg({'Sales':'sum', 'Profit':'sum'}).reset_index()\n\n# Visualize sales and profit with a bar chart\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Segment', y='Sales', data=segment_analysis, color='#9B60A1', label='Sales')\nsns.barplot(x='Segment', y='Profit', data=segment_analysis, color='salmon', label='Profit')\nplt.title('Sales and Profit by Customer Segment')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculate profit margin and add to DataFrame\nsegment_analysis['Profit Margin'] = (segment_analysis['Profit'] / segment_analysis['Sales']) * 100\n\n#Visualize profit margin\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Segment', y='Profit Margin', data=segment_analysis, palette='magma')\nplt.title('Profit Margin by Customer Segment')\nplt.ylabel('Profit Margin (%)')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; padding: 15px; background-color: rgba(173, 216, 230, 0.5); font-size: 100%; text-align: left;\">\n\nCorporate and Home Office segments show significant contributions but at a lower scale, indicating varied customer base profitability.\n\n__Profit margins are relatively consistent across segments,__ with Home Office slightly higher, suggesting efficient profitability despite lower sales volume.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"Category\"></a>\n<div style=\"background-color: rgba(173, 216, 230, 0.7); color:#0b8549; font-size:140%; font-family:'Comic Sans MS', cursive, sans-serif; text-align:center; border-radius:20px; padding:10px; box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);\">\n    <span style='#fcc36d;'>Step 3.5 |</span><span style='color:#9B60A1;'> Data Analysis (Sales, Profits and Profit Margin by Category)</span>\n</div>\n<a href=\"#contents_tabel\" style=\"display:block; text-align:center; margin-top:10px; text-decoration:none; color:#9B60A1; font-family:'Comic Sans MS', cursive, sans-serif;\">⬆️ Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"def visualize_sales_profit(df, group_by='State', group_column=None, top=True):\n    # Aggregate data\n    if group_column is None:\n        group_column = group_by\n    \n    agg_data = df.groupby(group_column).agg({'Sales': 'sum', 'Profit': 'sum'}).reset_index()\n    \n    if top:\n        agg_data = agg_data.sort_values(by='Sales', ascending=False).head(10)\n        title_top_bottom = 'Top'\n    else:\n        agg_data = agg_data.sort_values(by='Sales', ascending=True).head(10)\n        title_top_bottom = 'Bottom'\n    \n    # Visualize\n    g = sns.catplot(\n        data=agg_data.melt(id_vars=[group_column], value_vars=['Sales', 'Profit']),\n        kind='bar',\n        x='value',\n        y=group_column,\n        hue='variable',\n        palette=['#9B60A1', 'salmon'],\n        height=10, aspect=1,\n        legend=False\n    )\n    g.despine(left=True)\n    g.set_axis_labels(\"Total Amount ($)\", group_by)\n    g.ax.legend(title=\"Metrics\")\n    g.fig.suptitle(f'{title_top_bottom} 10 by Total Sales and Their Total Profit, Grouped by {group_column}', fontsize=16)\n    g.fig.set_facecolor((173/255, 216/255, 230/255, 0.5))\n    plt.legend(loc='upper right')\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_profit_margin(df, group_by='State', group_column=None, top=True):\n    # Aggregate data\n    if group_column is None:\n        group_column = group_by\n    \n    agg_data = df.groupby(group_column).agg({'Sales': 'sum', 'Profit': 'sum'}).reset_index()\n    \n    # Calculate profit margin\n    agg_data['Profit Margin'] = (agg_data['Profit'] / agg_data['Sales']) * 100\n    \n    if top:\n        agg_data = agg_data.sort_values(by='Profit Margin', ascending=False).head(10)\n        title_top_bottom = 'Top'\n    else:\n        agg_data = agg_data.sort_values(by='Profit Margin', ascending=True).head(10)\n        title_top_bottom = 'Bottom'\n    \n    # Visualize\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Profit Margin', y=group_column, data=agg_data, palette='magma')\n    plt.title(f'{title_top_bottom} 10 by Profit Margin, Grouped by {group_column}')\n    plt.xlabel('Profit Margin (%)')\n    plt.ylabel(group_column)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_sales_profit(df, group_by='Category', top=True)\nvisualize_profit_margin(df, group_by='Category', top=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; padding: 15px; background-color: rgba(173, 216, 230, 0.5); font-size: 100%; text-align: left;\">\n    \n__Sales and Profit by Category:__ __Technology leads in profits, despite similar sales volumes with Furniture, indicating higher profitability per item sold or a higher price point in this category.__ When it comes to Office Supplies, while having the highest sales, show comparatively lower profit, suggesting a volume-driven but lower-margin business model.  \n\n__Profit Margin by Category:__ __Technology stands out with the highest profit margin, reinforcing its position as the most lucrative category, likely due to premium pricing and product demand.__ When it comes to __Furniture, despite significant sales, has the lowest profit margin,__ indicating potential areas for cost reduction or pricing adjustments to enhance profitability. Office Supplies, on the other hand, maintain a steady profit margin, supporting a consistent, albeit less profitable, revenue stream compared to Technology.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"BySubCategory\"></a>\n<div style=\"background-color: rgba(173, 216, 230, 0.7); color:#0b8549; font-size:140%; font-family:'Comic Sans MS', cursive, sans-serif; text-align:center; border-radius:20px; padding:10px; box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);\">\n    <span style='#fcc36d;'>Step 3.6 |</span><span style='color:#9B60A1;'> Data Analysis (Sales, Profits and Profit Margin by Sub-Categories)</span>\n</div>\n<a href=\"#contents_tabel\" style=\"display:block; text-align:center; margin-top:10px; text-decoration:none; color:#9B60A1; font-family:'Comic Sans MS', cursive, sans-serif;\">⬆️ Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"visualize_sales_profit(df, group_by='Sub-Category', top=True)\nvisualize_sales_profit(df, group_by='Sub-Category', top=False)\nvisualize_profit_margin(df, group_by='Sub-Category', top=True)\nvisualize_profit_margin(df, group_by='Sub-Category', top=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; padding: 15px; background-color: rgba(173, 216, 230, 0.5); font-size: 100%; text-align: left;\">\n    \n__High Sales with Varied Profitability:__ Products like Phones and Chairs demonstrate high sales volumes, suggesting strong consumer demand. However, not all high-sales categories exhibit equally high profits, indicating that sales volume does not directly correlate with profitability. For example, Tables show significant sales but their profit contribution is less impressive, hinting at potential issues with pricing strategies, cost management, or both.  \n\n__High-Margin Niches:__ The analysis uncovers niche areas such as Copiers and Accessories that, although they may not top the sales charts, boast high profit margins. This suggests that focusing on these areas could yield substantial returns on relatively lower sales volumes. Such niches represent strategic opportunities for targeted marketing and inventory management to maximize profit margins.  \n\n__Challenges in Low-Margin Categories:__ Sub-categories like Tables and Bookcases emerge as areas with lower profit margins, some even dipping into negative territory. This highlights the need for strategic review and operational adjustments to tackle high costs, competitive pricing, or other market factors impacting profitability negatively.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"ByStates\"></a>\n<div style=\"background-color: rgba(173, 216, 230, 0.7); color:#0b8549; font-size:140%; font-family:'Comic Sans MS', cursive, sans-serif; text-align:center; border-radius:20px; padding:10px; box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);\">\n    <span style='#fcc36d;'>Step 3.7 |</span><span style='color:#9B60A1;'> Data Analysis (Sales, Profits and Profit Margin by States)</span>\n</div>\n<a href=\"#contents_tabel\" style=\"display:block; text-align:center; margin-top:10px; text-decoration:none; color:#9B60A1; font-family:'Comic Sans MS', cursive, sans-serif;\">⬆️ Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"visualize_sales_profit(df, group_by='State', top=True)\nvisualize_sales_profit(df, group_by='State', top=False)\nvisualize_profit_margin(df, group_by='State', top=True)\nvisualize_profit_margin(df, group_by='State', top=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; padding: 15px; background-color: rgba(173, 216, 230, 0.5); font-size: 100%; text-align: left;\">\n    \n__Top Performers__ like California and New York drive significant sales, indicating strong market demand.  \n    \n__Bottom Performers__ such as North Dakota and Wyoming may require strategic focus to unlock potential.  \n    \n__Profit Margin Analysis__ shows regions like Delaware with high efficiency, suggesting areas for operational optimization.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"ByCities\"></a>\n<div style=\"background-color: rgba(173, 216, 230, 0.7); color:#0b8549; font-size:140%; font-family:'Comic Sans MS', cursive, sans-serif; text-align:center; border-radius:20px; padding:10px; box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);\">\n    <span style='#fcc36d;'>Step 3.8 |</span><span style='color:#9B60A1;'> Data Analysis (Sales, Profits and Profit Margin by Cities)</span>\n</div>\n<a href=\"#contents_tabel\" style=\"display:block; text-align:center; margin-top:10px; text-decoration:none; color:#9B60A1; font-family:'Comic Sans MS', cursive, sans-serif;\">⬆️ Table of Contents</a>","metadata":{}},{"cell_type":"code","source":"visualize_sales_profit(df, group_by='City', top=True)\nvisualize_sales_profit(df, group_by='City', top=False)\nvisualize_profit_margin(df, group_by='City', top=True)\nvisualize_profit_margin(df, group_by='City', top=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; padding: 15px; background-color: rgba(173, 216, 230, 0.5); font-size: 100%; text-align: left;\">\n    \n__Major Cities Drive Sales:__ Top cities like New York and Los Angeles lead in both sales and profits, highlighting urban areas as key markets for retail success.  \n\n__Variability in Profitability:__ Despite high sales, profit contributions vary significantly across cities, pointing towards differences in operational efficiency, cost structures, or consumer preferences.  \n\n__High Profit Margins in Specific Cities:__ Cities like Atlantic City and New Brunswick show high profit margins, suggesting niche markets or effective cost management strategies that maximize profitability.  \n\n__Challenges in Smaller Cities:__ The bottom performers by profit margin, including Abilene and Mesquite, indicate areas where retail operations may be less efficient or face market challenges.","metadata":{}}]}